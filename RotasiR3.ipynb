{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def custom_round(n):\n",
    "    return math.ceil(n) if n % 1 >= 0.5 else math.floor(n)\n",
    "\n",
    "def calculate_dos(stock, sales):\n",
    "    return custom_round((stock / sales * 30)) if sales != 0 else 0\n",
    "\n",
    "def split_store(df, category_col_name):\n",
    "    df_asal = df[\n",
    "        ((df['DOS 30 days'] >= 30) & (df['Stock'] >= 2)) |\n",
    "        ((df['Sales 30 days'] >= 0) & (df['Stock'] >= 2))\n",
    "    ]\n",
    "    df_asal = df_asal[[f\"{category_col_name}\", \"STORE\", \"Article code no color\", \"Stock\", \"Sales 30 days\", \"DOS 30 days\"]]\n",
    "    \n",
    "    df_tujuan = df[\n",
    "        (df['DOS 30 days'] <= 23) &\n",
    "        (df['Sales 30 days'] != 0)\n",
    "    ]\n",
    "    df_tujuan = df_tujuan[[f\"{category_col_name}\", \"STORE\", \"Article code no color\", \"Stock\", \"Sales 30 days\", \"DOS 30 days\"]]\n",
    "    \n",
    "    return df_asal, df_tujuan\n",
    "\n",
    "def rotate_stock(df_asal, df_tujuan, category_col_name):\n",
    "    log_rotasi = pd.DataFrame(columns=[f\"{category_col_name}\", \"STORE ASAL\", \"ARTICLE\", \"BARANG TEROTASI\", \"STORE TUJUAN\"])\n",
    "    i = 0\n",
    "    # store asal dan tujuan tidak boleh kosong\n",
    "    while True:\n",
    "        dos_df_asal = list(df_asal['DOS 30 days'])\n",
    "        dos_df_tujuan = list(df_tujuan['DOS 30 days'])\n",
    "        \n",
    "        # Pilih store asal dengan melihat dos simulasi terbesar\n",
    "        df_asal = df_asal.sort_values(by=['DOS 30 days','Stock'], ascending=[False, False]).reset_index(drop=True)\n",
    "        \n",
    "        df_asal['Simulated Sales 30 days'] = df_asal['Sales 30 days'].where(df_asal['Sales 30 days'] != 0, 1)\n",
    "        simulated_doses = []\n",
    "        for index, row in df_asal.iterrows():\n",
    "            simulated_stock = row['Stock'] - 1\n",
    "            simulated_dos = calculate_dos(simulated_stock, row['Simulated Sales 30 days'])\n",
    "            simulated_doses.append(simulated_dos)\n",
    "        df_asal.drop('Simulated Sales 30 days', axis=1, inplace=True)\n",
    "        \n",
    "        selected_index = simulated_doses.index(max(simulated_doses))\n",
    "        asal = df_asal.loc[selected_index]\n",
    "\n",
    "        # buat kondisi dimana rotasi stok di hentikan\n",
    "        if (simulated_doses[selected_index] < 23) or all(x >= 23 for x in dos_df_tujuan):\n",
    "            # dos asal yang disimulasikan akan di rotasi kurang dari 23, stop\n",
    "            # semua store tujuan sudah memiliki dos lebih dari 23, stop\n",
    "            break\n",
    "\n",
    "        # Pilih store tujuan dengan DOS terendah yang memiliki sales tertinggi\n",
    "        df_tujuan = df_tujuan.sort_values(by=['DOS 30 days', 'Sales 30 days'], ascending=[True, False]).reset_index(drop=True)\n",
    "        tujuan = df_tujuan.loc[0]\n",
    "\n",
    "        # Update stok dan hitung ulang DOS untuk store asal dan tujuan\n",
    "        df_asal.at[selected_index, 'Stock'] -= 1\n",
    "        df_tujuan.at[0, 'Stock'] += 1\n",
    "        df_asal.at[selected_index, 'DOS 30 days'] = calculate_dos(df_asal.at[selected_index, 'Stock'], df_asal.at[selected_index, 'Sales 30 days'])\n",
    "        df_tujuan.at[0, 'DOS 30 days'] = calculate_dos(df_tujuan.at[0, 'Stock'], df_tujuan.at[0, 'Sales 30 days'])\n",
    "\n",
    "        new_log_entry = pd.DataFrame({\n",
    "            f\"{category_col_name}\": [asal[f'{category_col_name}']],\n",
    "            \"STORE ASAL\": [f\"{asal['STORE']}\"],\n",
    "            \"ARTICLE\": [asal['Article code no color']],\n",
    "            \"BARANG TEROTASI\": [1],\n",
    "            \"STORE TUJUAN\": [f\"{tujuan['STORE']}\"]\n",
    "        })\n",
    "        \n",
    "        log_rotasi = pd.concat([log_rotasi, new_log_entry], ignore_index=True)\n",
    "        \n",
    "        i += 1\n",
    "        # print(f'{i}.',asal['STORE'], 'ke' ,tujuan['STORE'])\n",
    "    \n",
    "    return df_asal, df_tujuan, log_rotasi\n",
    "\n",
    "############################\n",
    "def split_log_rotasi(log_rotasi, category_col_name):\n",
    "    # Membuat tabel store asal beserta stok yang bisa dirotasikan\n",
    "    tabel_asal = log_rotasi.groupby([f\"{category_col_name}\", \"ARTICLE\", \"STORE ASAL\"])['BARANG TEROTASI'].sum().reset_index()\n",
    "    tabel_asal.rename(columns={'BARANG TEROTASI': 'TOTAL TEROTASI'}, inplace=True)\n",
    "\n",
    "    # Membuat tabel store tujuan beserta stok yang dibutuhkan\n",
    "    tabel_tujuan = log_rotasi.groupby([f\"{category_col_name}\", \"ARTICLE\", \"STORE TUJUAN\"])['BARANG TEROTASI'].sum().reset_index()\n",
    "    tabel_tujuan.rename(columns={'BARANG TEROTASI': 'TOTAL BUTUH'}, inplace=True)\n",
    "\n",
    "    return tabel_asal, tabel_tujuan\n",
    "\n",
    "def reorder(log_rotasi):\n",
    "    df_sorted = log_rotasi.sort_values(by=['TOTAL ASAL'], ascending=[False]).reset_index(drop=True)\n",
    "\n",
    "    df_temp = pd.DataFrame(df_sorted.iloc[0]).transpose()\n",
    "    df_sorted.drop(0, inplace=True)\n",
    "\n",
    "    threshold = 0\n",
    "    while not df_sorted.empty:\n",
    "        df_sorted.reset_index(drop=True, inplace=True)\n",
    "        last_name = df_temp['STORE TUJUAN'].iloc[-1] if not df_temp.empty else None\n",
    "\n",
    "        for index_sorted, row_sorted in df_sorted.iterrows():\n",
    "            if last_name == row_sorted['STORE TUJUAN']:\n",
    "                df_temp = pd.concat([df_temp, pd.DataFrame([row_sorted])], ignore_index=True)\n",
    "                df_sorted.drop(index_sorted, inplace=True)\n",
    "                break\n",
    "\n",
    "        new_threshold = len(df_temp)\n",
    "        if threshold == new_threshold:\n",
    "            new_row = df_sorted.iloc[[0]] \n",
    "            df_temp = pd.concat([df_temp, new_row], ignore_index=True)\n",
    "            df_sorted.drop(0, inplace=True)\n",
    "            df_sorted.reset_index(drop=True, inplace=True)\n",
    "        threshold = new_threshold\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "def process_pairing_1(tabel_asal, tabel_tujuan, paired, category_col_name):\n",
    "    for index_asal, row_asal in tabel_asal.iterrows():\n",
    "        for index_tujuan, row_tujuan in tabel_tujuan.iterrows():\n",
    "            if row_asal['TOTAL TEROTASI'] == row_tujuan['TOTAL BUTUH']:\n",
    "                new_entry = pd.DataFrame({\n",
    "                    f\"{category_col_name}\": [row_asal[f\"{category_col_name}\"]],\n",
    "                    \"STORE ASAL\": [row_asal['STORE ASAL']],\n",
    "                    \"ARTICLE\": [row_asal['ARTICLE']],\n",
    "                    \"TOTAL ASAL\": [row_asal['TOTAL TEROTASI']],\n",
    "                    \"BARANG TEROTASI\": [min(row_asal['TOTAL TEROTASI'], row_tujuan['TOTAL BUTUH'])],\n",
    "                    \"TOTAL TUJUAN\": [row_tujuan['TOTAL BUTUH']],\n",
    "                    \"STORE TUJUAN\": [row_tujuan['STORE TUJUAN']]\n",
    "                })\n",
    "                paired = pd.concat([paired, new_entry], ignore_index=True)\n",
    "                tabel_asal.drop(index_asal, inplace=True)\n",
    "                tabel_tujuan.drop(index_tujuan, inplace=True)\n",
    "                \n",
    "                return tabel_asal, tabel_tujuan, paired \n",
    "    return tabel_asal, tabel_tujuan, paired\n",
    "\n",
    "def process_pairing_2(tabel_asal, tabel_tujuan, paired, category_col_name):\n",
    "    tabel_asal['Simulated TOTAL TEROTASI'] = tabel_asal['TOTAL TEROTASI']\n",
    "    tabel_tujuan['Simulated TOTAL BUTUH'] = tabel_tujuan['TOTAL BUTUH']\n",
    "\n",
    "    paired_temp = pd.DataFrame(columns=[f\"{category_col_name}\", 'STORE ASAL', 'ARTICLE', 'TOTAL ASAL', 'BARANG TEROTASI', 'TOTAL TUJUAN', 'STORE TUJUAN'])\n",
    "\n",
    "    while True:\n",
    "        tabel_asal = tabel_asal.sort_values(by=['Simulated TOTAL TEROTASI'], ascending=[False]).reset_index(drop=True)\n",
    "        tabel_tujuan = tabel_tujuan.sort_values(by=['Simulated TOTAL BUTUH'], ascending=[False]).reset_index(drop=True)\n",
    "\n",
    "        new_entry = pd.DataFrame({\n",
    "            f\"{category_col_name}\" : [tabel_asal.loc[0, f\"{category_col_name}\"]],\n",
    "            'STORE ASAL' : [tabel_asal.loc[0, 'STORE ASAL']],\n",
    "            'ARTICLE' : [tabel_asal.loc[0, 'ARTICLE']],\n",
    "            'TOTAL ASAL' : [tabel_asal.loc[0, 'TOTAL TEROTASI']],\n",
    "            'BARANG TEROTASI' : min(tabel_asal.loc[0, 'Simulated TOTAL TEROTASI'], tabel_tujuan.loc[0, 'Simulated TOTAL BUTUH']),\n",
    "            'TOTAL TUJUAN' : [tabel_tujuan.loc[0, 'TOTAL BUTUH']],\n",
    "            'STORE TUJUAN' : [tabel_tujuan.loc[0, 'STORE TUJUAN']]\n",
    "        })\n",
    "        \n",
    "        paired_temp = pd.concat([paired_temp, new_entry], ignore_index=True)\n",
    "\n",
    "        tabel_asal.loc[0, 'Simulated TOTAL TEROTASI'] -= new_entry['BARANG TEROTASI'].item()\n",
    "        tabel_tujuan.loc[0, 'Simulated TOTAL BUTUH'] -= new_entry['BARANG TEROTASI'].item()\n",
    "            \n",
    "        if all(x == 0 for x in tabel_tujuan['Simulated TOTAL BUTUH']) : \n",
    "            tabel_asal = pd.DataFrame(columns=tabel_asal.columns)\n",
    "            tabel_tujuan = pd.DataFrame(columns=tabel_tujuan.columns)\n",
    "            break        \n",
    "\n",
    "    paired_temp = reorder(paired_temp)\n",
    "    paired = pd.concat([paired, paired_temp], ignore_index=True)\n",
    "    \n",
    "    return tabel_asal, tabel_tujuan, paired\n",
    "\n",
    "def efficiency(log_rotasi, category_col_name):\n",
    "    paired = pd.DataFrame(columns=[f\"{category_col_name}\", 'STORE ASAL', 'ARTICLE', 'TOTAL ASAL', 'BARANG TEROTASI', 'TOTAL TUJUAN', 'STORE TUJUAN'])\n",
    "    tabel_asal, tabel_tujuan = split_log_rotasi(log_rotasi, category_col_name)\n",
    "\n",
    "    # Loop hingga salah satu atau kedua tabel kosong\n",
    "    threshold = 0\n",
    "    while not tabel_asal.empty and not tabel_tujuan.empty:\n",
    "        tabel_asal, tabel_tujuan, paired = process_pairing_1(tabel_asal, tabel_tujuan, paired, category_col_name)\n",
    "        \n",
    "        new_threshold = len(tabel_asal) * len(tabel_tujuan)\n",
    "        if threshold == new_threshold and new_threshold != 0 :\n",
    "            tabel_asal, tabel_tujuan, paired = process_pairing_2(tabel_asal, tabel_tujuan, paired, category_col_name)\n",
    "        threshold = new_threshold\n",
    "\n",
    "    return paired\n",
    "\n",
    "############################\n",
    "def add_dos_information(df_asal, df_asal_updated, df_tujuan, df_tujuan_updated, log_rotasi, category_col_name):\n",
    "    merged_data = pd.merge(\n",
    "        log_rotasi, df_asal[['STORE', 'Stock', 'Sales 30 days', 'DOS 30 days']],left_on='STORE ASAL', right_on='STORE', \n",
    "        how='left', suffixes=('', '_asal')).drop(columns=['STORE'])  \n",
    "\n",
    "    merged_data = pd.merge(\n",
    "        merged_data, df_asal_updated[['STORE', 'Stock', 'Sales 30 days', 'DOS 30 days']], left_on='STORE ASAL', right_on='STORE', \n",
    "        how='left',suffixes=('_asal_sebelum', '_asal_setelah')).drop(columns=['STORE'])\n",
    "\n",
    "    merged_data = pd.merge(\n",
    "        merged_data, df_tujuan[['STORE', 'Stock', 'Sales 30 days', 'DOS 30 days']], left_on='STORE TUJUAN', right_on='STORE', \n",
    "        how='left',suffixes=('', '_tujuan_sebelum')).drop(columns=['STORE'])\n",
    "\n",
    "    merged_data = pd.merge(\n",
    "        merged_data, df_tujuan_updated[['STORE', 'Stock', 'Sales 30 days', 'DOS 30 days']], left_on='STORE TUJUAN', right_on='STORE', \n",
    "        how='left',suffixes=('_tujuan_sebelum', '_tujuan_setelah')).drop(columns=['STORE'])\n",
    "\n",
    "    merged_data.rename(columns={\n",
    "        \"Stock_asal_sebelum\": \"Stock\", \"Sales 30 days_asal_sebelum\": \"Sales\", \"DOS 30 days_asal_sebelum\": \"Dos\",\n",
    "        \"Stock_asal_setelah\": \"Stock Akhir\", \"Sales 30 days_asal_setelah\": \"Sales Akhir\", \"DOS 30 days_asal_setelah\": \"Dos Akhir\",\n",
    "        \"Stock_tujuan_sebelum\": \"Stock Tujuan\", \"Sales 30 days_tujuan_sebelum\": \"Sales Tujuan\", \"DOS 30 days_tujuan_sebelum\": \"Dos Tujuan\",\n",
    "        \"Stock_tujuan_setelah\": \"Stock Akhir Tujuan\", \"Sales 30 days_tujuan_setelah\": \"Sales Akhir Tujuan\", \"DOS 30 days_tujuan_setelah\": \"Dos Akhir Tujuan\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    merged_data = merged_data[[\n",
    "        f\"{category_col_name}\", \"STORE ASAL\", \"ARTICLE\", \"Stock\", \"Sales\", \"Dos\", \"Stock Akhir\", \"Sales Akhir\", \"Dos Akhir\", \n",
    "        \"TOTAL ASAL\", \"BARANG TEROTASI\", \"TOTAL TUJUAN\", \"STORE TUJUAN\", \"Stock Tujuan\", \"Sales Tujuan\", \"Dos Tujuan\", \n",
    "        \"Stock Akhir Tujuan\", \"Sales Akhir Tujuan\", \"Dos Akhir Tujuan\"\n",
    "    ]]\n",
    "\n",
    "    return merged_data\n",
    "\n",
    "def rotate_by(df_pt, category_list, pt, category_col_name):\n",
    "    # category bisa by kota ataupun by tsh\n",
    "    rotasi = pd.DataFrame(columns=[\n",
    "        f\"{category_col_name}\", \"STORE ASAL\", \"ARTICLE\", \"Stock\", \"Sales\", \"Dos\", \"Stock Akhir\", \"Sales Akhir\", \"Dos Akhir\", \n",
    "        \"TOTAL ASAL\", \"BARANG TEROTASI\", \"TOTAL TUJUAN\", \"STORE TUJUAN\", \"Stock Tujuan\", \"Sales Tujuan\", \"Dos Tujuan\", \n",
    "        \"Stock Akhir Tujuan\", \"Sales Akhir Tujuan\", \"Dos Akhir Tujuan\"\n",
    "    ])\n",
    "\n",
    "    for category in tqdm(category_list, desc=f'Rotating {pt} by {category_col_name}'):\n",
    "        df_category = df_pt[df_pt[f'{category_col_name}'] == category]\n",
    "        articles = df_category[\"Article code no color\"].unique()\n",
    "\n",
    "        for article in articles:        \n",
    "            df_article = df_category[df_category['Article code no color'] == article]\n",
    "            df_asal, df_tujuan = split_store(df_article, category_col_name)\n",
    "            if not df_asal.empty and not df_tujuan.empty:\n",
    "                df_asal_updated, df_tujuan_updated, log_rotasi = rotate_stock(df_asal, df_tujuan, category_col_name)\n",
    "                log_rotasi = efficiency(log_rotasi, category_col_name)\n",
    "                log_rotasi = add_dos_information(df_asal, df_asal_updated, df_tujuan, df_tujuan_updated, log_rotasi, category_col_name)\n",
    "\n",
    "                rotasi = pd.concat([rotasi, log_rotasi], ignore_index=True)\n",
    "\n",
    "    # matikan jika memerlukan data total asal dan total tujuan\n",
    "    rotasi = rotasi.drop(columns=['TOTAL ASAL', 'TOTAL TUJUAN'])\n",
    "    return rotasi\n",
    "\n",
    "def merge_cells(worksheet, result_df, start_row, merge_format):\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    result_df['dummy'] = result_df['STORE ASAL'] + \"_\" + result_df['ARTICLE']\n",
    "    same_store_article = [(i,dummy) for i, dummy in enumerate(result_df['dummy'], start=start_row)]\n",
    "    indeks_dummy_list = []\n",
    "    dummy_list = []\n",
    "    \n",
    "    for row in same_store_article:\n",
    "        indeks_dummy_list.append(row)\n",
    "        dummy_list.append(row[1])\n",
    "            \n",
    "        if len(set(dummy_list)) > 1:\n",
    "            dummy_list_eksekusi = indeks_dummy_list[:-1]\n",
    "            n_dummy_list_eksekusi = len(dummy_list_eksekusi)\n",
    "            i = dummy_list_eksekusi[0][0]\n",
    "            base_index = i - start_row\n",
    "            worksheet.merge_range(i, 1, i + n_dummy_list_eksekusi - 1, 1, result_df['STORE ASAL'].iloc[base_index], merge_format)\n",
    "            worksheet.merge_range(i, 2, i + n_dummy_list_eksekusi - 1, 2, result_df['ARTICLE'].iloc[base_index], merge_format)\n",
    "            worksheet.merge_range(i, 3, i + n_dummy_list_eksekusi - 1, 3, result_df['Stock'].iloc[base_index], merge_format)\n",
    "            worksheet.merge_range(i, 4, i + n_dummy_list_eksekusi - 1, 4, result_df['Sales'].iloc[base_index], merge_format)\n",
    "            worksheet.merge_range(i, 5, i + n_dummy_list_eksekusi - 1, 5, result_df['Dos'].iloc[base_index], merge_format)\n",
    "            worksheet.merge_range(i, 6, i + n_dummy_list_eksekusi - 1, 6, result_df['Stock Akhir'].iloc[base_index], merge_format)\n",
    "            worksheet.merge_range(i, 7, i + n_dummy_list_eksekusi - 1, 7, result_df['Sales Akhir'].iloc[base_index], merge_format)\n",
    "            worksheet.merge_range(i, 8, i + n_dummy_list_eksekusi - 1, 8, result_df['Dos Akhir'].iloc[base_index], merge_format)\n",
    "\n",
    "            indeks_dummy_list = [indeks_dummy_list[-1]]\n",
    "            dummy_list = [dummy_list[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PT:   0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\gagah\\AppData\\Local\\Temp\\ipykernel_9356\\2298377865.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  rotasi = pd.concat([rotasi, log_rotasi], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EAR : Jumlah baris yang kolom 'Article'-nya NaN: 8\n",
      "(39417, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rotating EAR by KOTA: 100%|██████████| 75/75 [01:47<00:00,  1.43s/it]\n",
      "c:\\Users\\gagah\\miniconda3\\Lib\\site-packages\\xlsxwriter\\worksheet.py:2287: UserWarning: Can't merge single cell\n",
      "  warn(\"Can't merge single cell\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EAR : Jumlah baris yang kolom 'Article'-nya NaN: 8\n",
      "(39417, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagah\\AppData\\Local\\Temp\\ipykernel_9356\\2298377865.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  rotasi = pd.concat([rotasi, log_rotasi], ignore_index=True)\n",
      "Rotating EAR by TSH: 100%|██████████| 25/25 [01:40<00:00,  4.01s/it]\n",
      "c:\\Users\\gagah\\miniconda3\\Lib\\site-packages\\xlsxwriter\\worksheet.py:2287: UserWarning: Can't merge single cell\n",
      "  warn(\"Can't merge single cell\")\n",
      "Processing PT:  33%|███▎      | 1/3 [03:30<07:01, 210.61s/it]C:\\Users\\gagah\\AppData\\Local\\Temp\\ipykernel_9356\\2298377865.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  rotasi = pd.concat([rotasi, log_rotasi], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DCM : Jumlah baris yang kolom 'Article'-nya NaN: 0\n",
      "(2146, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rotating DCM by KOTA: 100%|██████████| 22/22 [00:07<00:00,  3.00it/s]\n",
      "c:\\Users\\gagah\\miniconda3\\Lib\\site-packages\\xlsxwriter\\worksheet.py:2287: UserWarning: Can't merge single cell\n",
      "  warn(\"Can't merge single cell\")\n",
      "C:\\Users\\gagah\\AppData\\Local\\Temp\\ipykernel_9356\\2298377865.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  rotasi = pd.concat([rotasi, log_rotasi], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DCM : Jumlah baris yang kolom 'Article'-nya NaN: 0\n",
      "(2146, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rotating DCM by TSH: 100%|██████████| 14/14 [00:07<00:00,  1.99it/s]\n",
      "c:\\Users\\gagah\\miniconda3\\Lib\\site-packages\\xlsxwriter\\worksheet.py:2287: UserWarning: Can't merge single cell\n",
      "  warn(\"Can't merge single cell\")\n",
      "Processing PT:  67%|██████▋   | 2/3 [03:45<02:31, 151.78s/it]C:\\Users\\gagah\\AppData\\Local\\Temp\\ipykernel_9356\\2298377865.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  rotasi = pd.concat([rotasi, log_rotasi], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NASA : Jumlah baris yang kolom 'Article'-nya NaN: 32\n",
      "(1838, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rotating NASA by KOTA: 100%|██████████| 22/22 [00:07<00:00,  2.76it/s]\n",
      "c:\\Users\\gagah\\miniconda3\\Lib\\site-packages\\xlsxwriter\\worksheet.py:2287: UserWarning: Can't merge single cell\n",
      "  warn(\"Can't merge single cell\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NASA : Jumlah baris yang kolom 'Article'-nya NaN: 32\n",
      "(1838, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gagah\\AppData\\Local\\Temp\\ipykernel_9356\\2298377865.py:243: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  rotasi = pd.concat([rotasi, log_rotasi], ignore_index=True)\n",
      "Rotating NASA by TSH: 100%|██████████| 15/15 [00:06<00:00,  2.15it/s]\n",
      "c:\\Users\\gagah\\miniconda3\\Lib\\site-packages\\xlsxwriter\\worksheet.py:2287: UserWarning: Can't merge single cell\n",
      "  warn(\"Can't merge single cell\")\n",
      "Processing PT: 100%|██████████| 3/3 [04:00<00:00, 80.06s/it] \n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# LOAD DATA\n",
    "file_name = \"Data Stock 9 Oct 2024.xlsx\"\n",
    "output_file = file_name[11:-5]\n",
    "file_path = f\"../ROTASI REGION 3/{file_name}\"\n",
    "master_path = \"../ROTASI REGION 3/MASTER REGION STO_NEXT VERSION (62).xlsx\"\n",
    "df_origin = pd.read_excel(file_path, sheet_name=\"dos by store-brand type & area\")\n",
    "df_master = pd.read_excel(master_path, sheet_name=\"REGION 3\", header=1)\n",
    "df_master_selected = df_master[['SITE CODE', 'PT']]\n",
    "df = pd.merge(df_origin, df_master_selected, on='SITE CODE', how='left')\n",
    "df['STORE'] = df['STORE NAME'] + \" (\" + df['SITE CODE'].astype(str) + \")\"\n",
    "df = df.drop(columns=['STORE NAME', 'SITE CODE'])\n",
    "df[['Sales 30 days', 'DOS 30 days']] = df[['Sales 30 days','DOS 30 days']].clip(lower=0).fillna(0)\n",
    "\n",
    "#############################################\n",
    "# KODE UTAMA\n",
    "output = \"C:/Users/gagah/Downloads/\"\n",
    "with pd.ExcelWriter(f'{output}RotasiR3 {output_file}.xlsx', engine='xlsxwriter') as writer:\n",
    "    for pt in tqdm(['EAR', 'DCM', 'NASA'], desc='Processing PT'):\n",
    "        for category_col_name in ['KOTA', 'TSH']:\n",
    "            df_pt = df[df['PT'] == pt]\n",
    "            \n",
    "            jumlah_baris_kosong = df_pt['Article code no color'].isnull().sum()\n",
    "            print(f\"\\n{pt} : Jumlah baris yang kolom 'Article'-nya NaN: {jumlah_baris_kosong}\")\n",
    "            df_pt = df_pt.dropna(subset=['Article code no color'])\n",
    "            print(df_pt.shape)\n",
    "\n",
    "            category_list = df_pt[f\"{category_col_name}\"].unique()\n",
    "            rotasi = rotate_by(df_pt, category_list, pt, category_col_name)\n",
    "\n",
    "            # Menyimpan hasil ke sheet yang berbeda dalam satu file Excel\n",
    "            rotasi.to_excel(writer, sheet_name=f'{pt} By {category_col_name}', index=False)\n",
    "\n",
    "            # merge cell\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[f'{pt} By {category_col_name}']\n",
    "            \n",
    "            merge_format = workbook.add_format({'valign': 'vcenter',})\n",
    "            merge_cells(worksheet, rotasi, 1, merge_format)\n",
    "\n",
    "#############################################\n",
    "# PROBLEM : TERDAPAT ARTICLE CODE NO COLOR YANG DUPLIKAT UNTUK SATU TOKO DI SATU KOTA\n",
    "# CONTOH : KOTA SEMARANG, M095, Redmi Note 13Pro5G 12/512, MEMILIKI STOK SALES DOS YANG BERBEDA\n",
    "\n",
    "#############################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
